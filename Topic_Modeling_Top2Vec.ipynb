{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Topic_Modeling_Top2Vec.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMHOo8HC7NJOxh3RGAd6FOv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dani-lbnl/mudit/blob/main/Topic_Modeling_Top2Vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Packages Installation"
      ],
      "metadata": {
        "id": "jOXE1SY3-lH8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bGDnrGh-UEr",
        "outputId": "d1938138-2b07-48bc-cd5c-8109fbaf11c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: llvmlite in /usr/local/lib/python3.7/dist-packages (0.34.0)\n",
            "Collecting llvmlite\n",
            "  Downloading llvmlite-0.38.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 34.5 MB 10 kB/s \n",
            "\u001b[?25hInstalling collected packages: llvmlite\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.34.0\n",
            "    Uninstalling llvmlite-0.34.0:\n",
            "      Successfully uninstalled llvmlite-0.34.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "numba 0.51.2 requires llvmlite<0.35,>=0.34.0.dev0, but you have llvmlite 0.38.0 which is incompatible.\u001b[0m\n",
            "Successfully installed llvmlite-0.38.0\n",
            "Collecting hdbscan\n",
            "  Cloning https://github.com/scikit-learn-contrib/hdbscan.git to /tmp/pip-install-uszjtan6/hdbscan_88f0f796c05f4d7fb33c7ddf206fef34\n",
            "  Running command git clone -q https://github.com/scikit-learn-contrib/hdbscan.git /tmp/pip-install-uszjtan6/hdbscan_88f0f796c05f4d7fb33c7ddf206fef34\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from hdbscan) (1.21.5)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from hdbscan) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.7/dist-packages (from hdbscan) (1.0.2)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.7/dist-packages (from hdbscan) (1.1.0)\n",
            "Requirement already satisfied: cython>=0.27 in /usr/local/lib/python3.7/dist-packages (from hdbscan) (0.29.28)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20->hdbscan) (3.1.0)\n",
            "Building wheels for collected packages: hdbscan\n",
            "  Building wheel for hdbscan (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hdbscan: filename=hdbscan-0.8.28-cp37-cp37m-linux_x86_64.whl size=2330737 sha256=188b239ab35edee11f8255b1803694fb03ebcc6a180798bb0f00e98af051547d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-mxfb3jol/wheels/ed/bc/7c/98e7b9e488cf4df55d46ecbbf01f1a3672914c4f8cee55fe19\n",
            "Successfully built hdbscan\n",
            "Installing collected packages: hdbscan\n",
            "Successfully installed hdbscan-0.8.28\n",
            "Collecting top2vec[sentence_encoders]\n",
            "  Downloading top2vec-1.0.26-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: hdbscan>=0.8.27 in /usr/local/lib/python3.7/dist-packages (from top2vec[sentence_encoders]) (0.8.28)\n",
            "Collecting umap-learn>=0.5.1\n",
            "  Downloading umap-learn-0.5.2.tar.gz (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 2.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wordcloud in /usr/local/lib/python3.7/dist-packages (from top2vec[sentence_encoders]) (1.5.0)\n",
            "Requirement already satisfied: gensim<4.0.0 in /usr/local/lib/python3.7/dist-packages (from top2vec[sentence_encoders]) (3.6.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from top2vec[sentence_encoders]) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.7/dist-packages (from top2vec[sentence_encoders]) (1.21.5)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from top2vec[sentence_encoders]) (2.8.0)\n",
            "Collecting tensorflow-text\n",
            "  Downloading tensorflow_text-2.8.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 43.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub in /usr/local/lib/python3.7/dist-packages (from top2vec[sentence_encoders]) (0.12.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim<4.0.0->top2vec[sentence_encoders]) (1.15.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim<4.0.0->top2vec[sentence_encoders]) (5.2.1)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim<4.0.0->top2vec[sentence_encoders]) (1.4.1)\n",
            "Requirement already satisfied: cython>=0.27 in /usr/local/lib/python3.7/dist-packages (from hdbscan>=0.8.27->top2vec[sentence_encoders]) (0.29.28)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.7/dist-packages (from hdbscan>=0.8.27->top2vec[sentence_encoders]) (1.0.2)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.7/dist-packages (from hdbscan>=0.8.27->top2vec[sentence_encoders]) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20->hdbscan>=0.8.27->top2vec[sentence_encoders]) (3.1.0)\n",
            "Requirement already satisfied: numba>=0.49 in /usr/local/lib/python3.7/dist-packages (from umap-learn>=0.5.1->top2vec[sentence_encoders]) (0.51.2)\n",
            "Collecting pynndescent>=0.5\n",
            "  Downloading pynndescent-0.5.6.tar.gz (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 45.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from umap-learn>=0.5.1->top2vec[sentence_encoders]) (4.63.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn>=0.5.1->top2vec[sentence_encoders]) (57.4.0)\n",
            "Collecting llvmlite<0.35,>=0.34.0.dev0\n",
            "  Downloading llvmlite-0.34.0-cp37-cp37m-manylinux2010_x86_64.whl (24.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 24.6 MB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->top2vec[sentence_encoders]) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->top2vec[sentence_encoders]) (2.8.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (1.13.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (3.10.0.2)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 73.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (1.6.3)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (0.5.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (3.3.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (3.1.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (2.8.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (2.8.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (1.44.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (13.0.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (2.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (0.24.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (3.17.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (0.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (1.0.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow->top2vec[sentence_encoders]) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow->top2vec[sentence_encoders]) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->top2vec[sentence_encoders]) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->top2vec[sentence_encoders]) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->top2vec[sentence_encoders]) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->top2vec[sentence_encoders]) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->top2vec[sentence_encoders]) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->top2vec[sentence_encoders]) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->top2vec[sentence_encoders]) (2.23.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->top2vec[sentence_encoders]) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->top2vec[sentence_encoders]) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->top2vec[sentence_encoders]) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->top2vec[sentence_encoders]) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->top2vec[sentence_encoders]) (4.11.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->top2vec[sentence_encoders]) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->top2vec[sentence_encoders]) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->top2vec[sentence_encoders]) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->top2vec[sentence_encoders]) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->top2vec[sentence_encoders]) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->top2vec[sentence_encoders]) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->top2vec[sentence_encoders]) (3.2.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from wordcloud->top2vec[sentence_encoders]) (7.1.2)\n",
            "Building wheels for collected packages: umap-learn, pynndescent\n",
            "  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for umap-learn: filename=umap_learn-0.5.2-py3-none-any.whl size=82708 sha256=5b15dfc5ea3b738d98d1290022f6a0f0a062bc68f118430f48661a522efcdf18\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/1b/c6/aaf68a748122632967cef4dffef68224eb16798b6793257d82\n",
            "  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pynndescent: filename=pynndescent-0.5.6-py3-none-any.whl size=53943 sha256=848fefe7e2edc4050c039c96f5e05aa3282f807e3f93fb5ad6b7ae46b0bafe61\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/f1/56/f80d72741e400345b5a5b50ec3d929aca581bf45e0225d5c50\n",
            "Successfully built umap-learn pynndescent\n",
            "Installing collected packages: llvmlite, tf-estimator-nightly, pynndescent, umap-learn, top2vec, tensorflow-text\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.38.0\n",
            "    Uninstalling llvmlite-0.38.0:\n",
            "      Successfully uninstalled llvmlite-0.38.0\n",
            "Successfully installed llvmlite-0.34.0 pynndescent-0.5.6 tensorflow-text-2.8.1 tf-estimator-nightly-2.8.0.dev2021122109 top2vec-1.0.26 umap-learn-0.5.2\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade llvmlite\n",
        "!pip install --upgrade git+https://github.com/scikit-learn-contrib/hdbscan.git#egg=hdbscan\n",
        "# !pip install top2vec  # easy way to install Top2Vec\n",
        "!pip install top2vec[sentence_encoders]  # install if using pre-trained universal sentence encoder options\n",
        "# !pip install top2vec[sentence_transformers]  # install if using pre-trained BERT sentence transformer options"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from top2vec import Top2Vec\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import multiprocessing\n",
        "import time\n",
        "\n",
        "multiprocessing.cpu_count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlSlCwsX-j-V",
        "outputId": "95905851-c4f6-41a0-d430-02737c4c2d2d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Top2Vec on pubs.xlsx"
      ],
      "metadata": {
        "id": "mOARRcMu-jjY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_table('/content/drive/MyDrive/LBNL/Pubs.xls')\n",
        "abstracts = list(df[~df['Abstract'].isna()]['Abstract'])\n",
        "\n",
        "corpus_abs, id2word_abs, words_abs = preprocess_lda(abstracts)"
      ],
      "metadata": {
        "id": "hXdfRfuA_Ioo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}